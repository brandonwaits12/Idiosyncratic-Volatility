{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin 585R**  \n",
    "**Diether**  \n",
    "**Problem Set**  \n",
    "**Dispersion Portfolios**  \n",
    "\n",
    "**Purpose/Goal**\n",
    "\n",
    "The purpose of this problem set is to give you a portfolio formation task that makes you go through the first four steps of our portfolio formation framework.\n",
    "\n",
    "1. Data Preparation.<br><br>\n",
    "\n",
    "2. Create portfolio formation or criterion variable.<br><br>\n",
    "\n",
    "3. Bin the data based on the formation variable.<br><br>\n",
    "\n",
    "4. Portfolio creeation using the bins.<br><br>\n",
    "\n",
    "5. Testing the historical performance.<br><br>\n",
    "\n",
    "You should be able to adapt a lot of code we've used before, and apply it this situation.\n",
    "\n",
    "**Overview**\n",
    "\n",
    "In this problem set you reproduce your second seminal empirical result in academic finance. Specifically, you reproduce the **dispersion effect** (or the analyst disgreement effect) of Diether, Malloy, and Scherbina (2002). This empirical result spawned a large literature in academic finance, and certainly some quant funds have tried to trade on this effect.\n",
    "\n",
    "Dispersion (or analyst disagreement) portfolios are formed based on the standard deviation of analyst eps (earnings per share) forecasts over a given period. Here the standard deviation of analyst eps forecasts is the standard deviation across analysts for a given stock and month. Diether, Malloy, and Scherbina don't use raw standard deviation. Instead, they scale standard deviation of analyst forecasts by the absolute value of the mean forecast. Therefore for a given month ($t$), dispersion for stock $i$ is defined as the following:\n",
    "\n",
    "$$\n",
    "disp_{it} = \\frac{stdev_{it}}{|mean_{it}|}\n",
    "$$\n",
    "\n",
    "DMS form dispersion portfolios using $disp_{i,t-1}$; in other words, they lag dispersion one month. In this homework you will do the same. Additionally, you will form dispersion portfolio based on laggin dispersion 3 months.\n",
    "\n",
    "There are two datasets for this problem set. The first is the CRSP data (security prices and returns) during the period from July of 1982 to December of 2000. The second is the analyst earnings per share data from IBES. It also covers the period of July of 1982 to December of 2000. The frequency for both datasets is monthly. The stock level identifier in the IBES data is called a CUSIP. Consequently, I also included CUSIPs in the CRSP data. The CUSIP and the calender month uniquely identify the analyst earnings per share observations.\n",
    "\n",
    "You can download the CRSP data directly using the following link: [the CRSP data](http://diether.org/prephd/08-mstk_82-00.csv). There is also a link on *Learning Suite*. The data contain the following variables:\n",
    "\n",
    "|Variable | Description                                              |\n",
    "|---------|----------------------------------------------------------|\n",
    "|permno   | stock identifier                                         |\n",
    "|cusip    | stock identifier also in IBES data                       |\n",
    "|caldt    | calendar date (the day is not truncated to 1)            |\n",
    "|ret      | monthly return                                           |\n",
    "|prc      | stock price (not lagged, contemporaneous with returns)   |   \n",
    "\n",
    "\n",
    "You can download the IBES data directly using the following link: [the IBES data](http://diether.org/prephd/08-ibes_eps_analyst.csv). There is also a link on *Learning Suite*. The data contain the following variables:\n",
    "\n",
    "|Variable | Description                                          |\n",
    "|---------|------------------------------------------------------|\n",
    "|cusip    | stock identifier also in IBES data                   |\n",
    "|caldt    | calendar date (the day is not truncated to 1)        |\n",
    "|meanest  | average analyst forecast for that month/stock        |\n",
    "|stdev    | standard deviation of forecasts for that month/stock |\n",
    "\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Form quintile based equal-weight dispersion portfolios where dispersion is lagged one month. Report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). Note, you should exclude low price stocks from your portfolios (price below $5). <br><br>\n",
    "\n",
    "2. Add a spread portfolio to your dataframe of dispersion portfolios. Report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio).<br><br>\n",
    "\n",
    "3. Compute the average number of stocks that are in each portfolio.<br><br>\n",
    "\n",
    "4. Form quintile based equal-weight dispersion portfolios where dispersion is lagged three month instead of one.  Report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). Note, you should exclude low price stocks from your portfolios (price below $5).<br><br>\n",
    "\n",
    "5. Compare the results from (1) and (4). What do either the differences or similarities in the average return pattern tell you about the nature of this dispersion effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk = pd.read_csv('08-mstk_82-00.csv',parse_dates=['caldt'])\n",
    "stk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes = pd.read_csv(\"08-ibes_eps_analyst.csv\",parse_dates=['caldt'])\n",
    "ibes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint About Merging the two Datasets**\n",
    "\n",
    "In the datasets I've include the full calender dates of the observations. Even though the frequency for both is monthly, the timing is not the same. The CRSP data is from the last trading day in the month, and the IBES data tends to be around the middle of the month. Therefore, to merge these dataframes you need to ctreate a new date variable that only preserve uniqueness at the year-month level. Here is a shortcut way to accomplish that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk['mdt'] = stk['caldt'].values.astype('datetime64[M]')\n",
    "stk.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes['mdt'] = ibes['caldt'].values.astype('datetime64[M]')\n",
    "ibes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the code above doing? Pandas stores all dates with precision to the nanosecond. But numpy (the library pandas uses for its date functionality) actually includes date types for varying levels of precision (including monthly). So the above code changes the original nanosecond datetype to a monthly datetype; this causes all the information about time beyond a month to be lost and when pandas automatically reconverts the date to a nanosecond datetype the day gets set equal to one for all observations.\n",
    "\n",
    "Now you should be able to merge the two datasets. I suggest you merge the ibes dataframe into the stk dataframe using a left merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibes = ibes.drop(columns=['caldt'])\n",
    "\n",
    "stk = stk.merge(ibes,on=['cusip','mdt'],how='left')\n",
    "stk.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dispersion Variable and Lagged Variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stk['disp'] = stk['stdev'] / np.abs(stk['meanest'])\n",
    "\n",
    "stk['displag'] = stk.groupby('permno')['disp'].shift()\n",
    "stk['displag3'] = stk.groupby('permno')['disp'].shift(3)\n",
    "stk['prclag'] = stk.groupby('permno')['prc'].shift()\n",
    "\n",
    "stk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1 and 2**\n",
    "\n",
    "+ Form equal-weight portfolios based on lagged dispersion.<br><br>\n",
    "\n",
    "+ Add a spread portfolio. Report summary statistics.<br><br>\n",
    "\n",
    "\n",
    "**Working off a new copy of the data**\n",
    "\n",
    "I'm going to work off sub-selection of the data I have the non-queried/selected data to go back to when I to the lagged three months dispersion based portfolios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stk.query(\"displag == displag and prclag >= 5\").reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bins'] = df.groupby('caldt')['displag'].transform(pd.qcut,5,labels=False)\n",
    "\n",
    "ew = (df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns')*100)\n",
    "ew.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_byu.summarize import summary\n",
    "\n",
    "ew['spr'] = ew['p0'] - ew['p4']\n",
    "summary(ew).loc[['count','mean','std','tstat','pval'],].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "+ Compute the average number of stocks in the portfolios.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['caldt','port'])['ret'].count().unstack(level='port').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "\n",
    "+ Form equal-weight portfolios based on three month lagged dispersion.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stk.query(\"displag3 == displag3 and prclag >= 5\").reset_index(drop=True)\n",
    "\n",
    "df['bins3'] = df.groupby('caldt')['displag3'].transform(pd.qcut,5,labels=False)\n",
    "\n",
    "ew = (df.groupby(['caldt','bins3'])['ret'].mean().unstack(level='bins3')\n",
    "      .rename('p{:.0f}'.format,axis='columns')*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew['spr'] = ew['p0'] - ew['p4']\n",
    "summary(ew).loc[['count','mean','std','tstat','pval'],].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
