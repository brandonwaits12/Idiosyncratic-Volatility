{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin 585R**  \n",
    "**Diether**  \n",
    "**Problem Set**  \n",
    "**Momentum Portfolios**  \n",
    "\n",
    "**Overview**\n",
    "\n",
    "In this problem set you reproduce your second seminal empirical result in academic finance. Specifically, you reproduce and extend (the original sample was about 1963 to 1990) **the momentum effect** of Jegadeesh and Titman (1993) (see \"Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency\"). This empirical result spawned a huge literature in academic finance, and has been a critical core strategy for quant hedge funds (and others) for the last 30 years. You will find out in the next couple of weeks that models like the CAPM can't explain this portfolio return pattern at all. \n",
    "\n",
    "Momentum portfolios are formed based on past returns. Specifically, momentum portfolios are most commonly formed based on the cumulative return from months $t-12$ to $t-2$ (you should use this past return window for your portfolios):\n",
    "\n",
    "$$\n",
    "r_{i,t-12:t-2} \\approx \\sum_{x=2}^{12} \\log(1+r_{i,t-x})\n",
    "$$\n",
    "\n",
    "Note, it's common practice to cumulate (or compound) the returns using the log approximation (as above). You certainly can do the following if you want (well, not for this problem set ... use log returns for the problem set):\n",
    "\n",
    "$$\n",
    "r_{i,t-12:t-2} = \\left[ \\prod_{x=2}^{12} \\bigl(1+r_{i,t-x} \\bigr) \\right]  - 1\n",
    "$$\n",
    "\n",
    "The log approximation is traditionally used in this situation because it's less computational intensive. \n",
    "\n",
    "The data for this problem set are monthly observations for all stocks on the NYSE, AMEX, and Nasdaq from July of 1962 to  September of 2022. You can download the data directly using the following link: [the data](https://diether.org/prephd/06-mstk_62-22.csv). There is also a link on *Learning Suite*. The data contain the following variables that you will need for the assignment (it also contains som additional variables):\n",
    "\n",
    "|Variable | Description                                              |\n",
    "|---------|----------------------------------------------------------|\n",
    "|permno   | stock identifier                                         |\n",
    "|caldt    | calendar date                                            |\n",
    "|ticker   | ticker symbol                                            |\n",
    "|prc      | stock price (not lagged, contemporaneous with returns)   |\n",
    "|me       | market equity (not lagged, contemporaneous with returns) |\n",
    "|ret      | monthly return                                           |\n",
    "|shr      | shares outstanding in 1000s                              |\n",
    "\n",
    "\n",
    "**Tasks**\n",
    "\n",
    "1. Form quintile based equal-weight momentum portfolios and report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). Note, you should exclude low price stocks from your portfolios (price below $5). We will discuss the code for creating the portfolio formation variable in the class before the assignment. <br><br>\n",
    "\n",
    "2. Compute the average number of stocks that are in each portfolio.<br><br>\n",
    "\n",
    "3. Add a spread portfolio (long portfolio 4 and short portfolio 0 $\\leftarrow$ it's a zero cost L/S portfolio) to your dataframe of equal-weight momentum portfolios and then compute the summary statistics.<br><br>\n",
    "\n",
    "4. Form quintile based value-weight momentum portfolios and report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). You should once again have five portfolios (note, the only difference between your equal-weight and value-weight portfolios will be the weights). Note, a value weight portfolio is defined as the following ($me$ refers to the marke value of equity): <br><br>\n",
    "$$\n",
    "r_{pt} = \\sum_{i=1}^{n} \\omega_{i}r_{it} = \\sum_{i=1}^{n} \\left(\\frac{me_{i,t-1}}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) r_{it}\n",
    "$$<br><br>\n",
    "Hint: think about splitting the formula into the following parts delineated by the parentheses:<br><br>\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\left( \\frac{1}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) \\left( \\sum_{i=1}^{n} me_{i,t-1} r_{it}\n",
    "          \\right)\n",
    " \\end{align*}<br><br>\n",
    "And then compute each part as a separate groupby. Finally, just multiple the resulting dataframes together and you will have computed the value-weight portfolio returns. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('06-mstk_62-23.csv',parse_dates=['caldt'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Portfolio Formation Variable: $r_{t-12,t-2}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logret'] = np.log(1 + df['ret'])\n",
    "df['mom'] = df.groupby('permno')['logret'].rolling(11,11).sum().reset_index(drop=True)\n",
    "df['mom'] = df.groupby('permno')['mom'].shift(2)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lag Variables and Remove Low Priced Stocks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prclag'] = df.groupby('permno')['prc'].shift()\n",
    "df['melag'] = df.groupby('permno')['me'].shift(1)\n",
    "\n",
    "df = df.query(\"mom == mom and prclag >= 5\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Portfolio Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bins'] = df.groupby('caldt')['mom'].transform(pd.qcut,5,labels=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**\n",
    "\n",
    "Form quintile based equal-weight momentum portfolios and report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')*100\n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_byu.summarize import summary\n",
    "summary(ew).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming the Columns**\n",
    "\n",
    "+ Can do it compactly with string formatter or an fstring<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = (df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns')*100)\n",
    "\n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = (df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')\n",
    "      .rename(lambda x: f'p{x:.0f}',axis='columns')*100)    \n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ew).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**\n",
    "\n",
    "Compute the average number of stocks that are in each portfolio.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(['caldt','bins'])['ret'].count().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(['caldt','bins'])['ret'].count().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns')).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**\n",
    "\n",
    "Add a spread portfolio (long portfolio 4 and short portfolio 0 $\\leftarrow$ it's a zero cost L/S portfolio) to your dataframe of equal-weight momentum portfolios and then compute the summary statistics.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew['spread'] = ew['p4'] - ew['p0']\n",
    "\n",
    "summary(ew).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**\n",
    "\n",
    "Create value-weight momentum portfolios.<br><br>\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\left( \\frac{1}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) \\left( \\sum_{i=1}^{n} me_{i,t-1} r_{it}\n",
    "          \\right)\n",
    " \\end{align*}<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcapsum = df.groupby(['caldt','bins'])['melag'].sum()\n",
    "\n",
    "df['rme'] = df['ret']*df['melag']\n",
    "vw = df.groupby(['caldt','bins'])['rme'].sum() / mcapsum\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = vw.unstack(level='bins').rename('p{:.0f}'.format,axis='columns')*100\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw['spread'] = vw['p4'] - vw['p0']\n",
    "\n",
    "summary(vw).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Alternate Value-Weighting Method**\n",
    "\n",
    "+ Conceptually Straight Forward, but Relatively Slow Execution.<br><br>\n",
    "\n",
    "+ I think the conceptually easiest way to create these value weight portfolios is to essentially compute the weights, multiple the weights, and then sum everything up in one function as part of a `groupby` call. The function in this case will have a pretty much direct correspondence with the mathematical formula:\n",
    "<br><br>\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\sum_{i=1}^{n} \\left(\\frac{me_{i,t-1}}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) r_{it}\n",
    "\\end{align*}<br><br>\n",
    "\n",
    "+ We will use `apply` instead of `transform` or `aggregate` because we are going to send in an Nx2 dataframe (returns and lagged market-cap) and then for each date/port group we are going to return a scalar portfolio return (so the dimensionality of the return is 1x1).<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def vw_port(x):\n",
    "    wtotal = x['melag'].sum()\n",
    "    return ((x['melag']/wtotal)*x['ret']).sum()\n",
    "\n",
    "vw = df.groupby(['caldt','bins'])[['ret','melag']].progress_apply(vw_port)\n",
    "vw = vw.unstack(level='bins')*100\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vw).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. A Little Speed Testing**\n",
    "\n",
    "Jupyter notebooks (really the underlying IPython kernel) make it easy to test the speed of different approaches. IPython has a magic function named `%timeit` that tests the speed of a function or single line of code. We can use `%timeit` to compare the speed of the two approaches for creating value-weight portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vw_one():\n",
    "    df['rme'] = df['ret']*df['melag']\n",
    "    vw = df.groupby(['caldt','bins'])['rme'].sum() / df.groupby(['caldt','bins'])['melag'].sum()\n",
    "    \n",
    "%timeit -n 1 -r 3 vw_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vw_two():\n",
    "    vw = df.groupby(['caldt','bins'])[['ret','melag']].apply(vw_port)\n",
    "\n",
    "%timeit -n 1 -r 3 vw_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is the first approach faster?**\n",
    "\n",
    "The first approach is much more efficient (fast) because it relies only on native `pandas'` methods. In general, relying as much as you can on methods from the groupby object that `pandas` provides natively will result in faster code. The reason for the faster speed is because most of `pandas'` methods and functions are written in the `C` programming language, and the C programming language is very fast. Technically most of `pandas'` functions and methods are written in a language called `Cython` which can be translated or \"compiled\" into `C`. When you supply a custom function to `pandas` (even a simple one like `vw_weight`) `pandas` usually has to execute much more of the process in `python` rather than `C`.\n",
    "\n",
    "Also, any operations you can compute on a whole column at once rather than as part of a function called by a `groupby` will be faster (we did that with one operation above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
